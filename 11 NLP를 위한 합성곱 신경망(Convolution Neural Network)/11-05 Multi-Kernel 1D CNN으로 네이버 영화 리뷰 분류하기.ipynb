{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11-05 Multi-Kernel 1D CNN으로 네이버 영화 리뷰 분류하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 데이터 수집 & 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 전처리는 RNN을 이용한 텍스트 분류 챕터의 네이버 영화 리뷰 분류하기( https://wikidocs.net/44249 )와 동일하게 수행"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Kernel 1D CNN으로 네이버 영화 리뷰 분류하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에서 다수의 커널을 사용할 경우에는 Funtional API를 사용하여 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "embedding_dim = 128\n",
    "dropout_ratio = (0.5, 0.8)\n",
    "num_filters = 128\n",
    "hidden_units = 128\n",
    "\n",
    "model_input = Input(shape = (max_len,))\n",
    "z = Embedding(vocab_size, embedding_dim, input_length = max_len, name=\"embedding\")(model_input)\n",
    "z = Dropout(dropout_ratio[0])(z)\n",
    "\n",
    "conv_blocks = []\n",
    "\n",
    "for sz in [3, 4, 5]:\n",
    "    conv = Conv1D(filters = num_filters,\n",
    "                    kernel_size = sz,\n",
    "                    padding = \"valid\",\n",
    "                    activation = \"relu\",\n",
    "                    strides = 1)(z)\n",
    "    conv = GlobalMaxPooling1D()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = Dropout(dropout_ratio[1])(z)\n",
    "z = Dense(hidden_units, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('CNN_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2, verbose=2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('CNN_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리뷰 예측해보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN을 이용한 텍스트 분류 챕터의 네이버 영화 리뷰 분류하기 실습( https://wikidocs.net/44249 )에서 사용한 동일한 예측 함수 sentiment_predict를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
